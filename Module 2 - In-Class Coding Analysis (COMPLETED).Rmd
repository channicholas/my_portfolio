---
title: "Module 2 - Simple Linear Regression Model Assumptions"
subtitle: <center> <h1>In-Class Analysis</h1> </center>
output: html_document
---

<style type="text/css">
h1.title {
  font-size: 40px;
  text-align: center;
}
</style>

```{r setup, include=FALSE}
# load packages here
library(tidyverse)
library(ggfortify)  # plot lm objects using ggplot instead of base R
sz <- 16
```

## Data and Description

A country's fertility rate is a key indicator that reflects demographic trends and 
socioeconomic well being, and macroeconomists often desire to model the dependence of 
this rate on other key indicators.  In this coding exercise, we will investigate the 
effets of a country's per capita gross domestic product on the fertility rate using 
a data set of $n = 199$ countries, specifically the `UN11` data set and its 
variables **fertility** and **ppgdp**.

We will see that a simple linear regression model is not appropriate for these variables, 
and will investigate transformations in order to produce a valid simple linear regression 
model.

Do the following:

1. Load the `alr4` package and examine the first few rows of the `UN11` data set.
2. Create a scatterplot of the data with **ppgdp** on the x-axis and **fertility** on the y-axis, and overlay the linear regression line.
3. Apply linear regression to the data (call the fitted model variable `fert.lm`), and save the residuals and fitted values to the `UN11` data frame.

```{r}
library(alr4)
fert.base.plot <- ggplot(data = UN11, mapping = aes(x = ppgdp, y = fertility)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE) + 
  labs(x = "Per Capita GDP (US Dollars)", y = "Fertility (#Children per Woman)")
fert.base.plot
fert.lm <- lm(fertility ~ ppgdp, data = UN11)
```

## Diagnostics: Check if Assumptions are Met

In turn, check each assumption of linear regression.  Create the appropriate plot(s)
and describe what it reflects about the plausibility of the relevant regression assumption(s).

### 1. Linearity

**(a) Scatterplot**

```{r, fig.align='center'}
fert.base.plot
```

The plot shows a clear violation of linearity, since the vertical trend seen in the points 
does not change linearly from left to right.  For instance, the is a huge drop in 
fertility between ppgdp values of 5000-1000, where as the decrease is more subtle 
after that point.

**(b) Residuals vs. Fitted Values Plot**


```{r, fig.align='center'}
## The code below will generate the residuals vs. fitted values plot by using
## the information in fert.lm.  The argument 'which = 1' is how R knows that
## we are asking it to produce a Res vs. Fitted plot.
#
autoplot(fert.lm, which = 1, ncol = 1, nrow = 1) +
  theme_bw() + 
  scale_y_continuous(limits = c(-3.8, 3.8)) +
  scale_x_continuous(limits = c(-0.5, 3.5)) +
  theme(axis.title.x = element_text(size = sz),
        axis.title.y = element_text(size = sz),
        axis.text = element_text(size = sz),
        aspect.ratio = 1)
```

The residuals are not centered around 0 for all fitted values.  For instance, the
8 residuals corresponding to the smallest fitted values (those below 1.5) are all positive.
For fitted values between 1.5 and 3, the vast majority of residuals are negative. Linearity is violated.

### 2. Equal Variance

**(a) Scale-Location plot **

```{r}
## Using 'which = 3' produces the scale-location plot

autoplot(fert.lm, which = 3, ncol = 1, nrow = 1) +
  theme_bw() + 
  scale_y_continuous(limits = c(0, 2)) +
  scale_x_continuous(limits = c(-0.5, 3.5)) +
  theme(axis.title.x = element_text(size = sz),
        axis.title.y = element_text(size = sz),
        axis.text = element_text(size = sz),
        aspect.ratio = 1)
```

The blue curve indicates an unequal trend in the spread of the error distribution
across different fitted values.  Noticeably, the variability in the standardized 
residuals is much larger for observations with fitted values near 3 than for fitted 
values between 1 and 3, for example.  Equal variance is violated.

### 3. The errors $\epsilon_i$ are independent across $i$.

This assumption is difficult to test statistically. Generally, if you have a random sample, the residuals will be independent. *If* the observations in this data set were in a natural order, then we could use a sequence plot to assess dependence, but a sequence plot is inappropriate here since the data are not in a natural order. Below is the code to create a sequence plot (indexed by row), for your reference.

**(a) Sequence Plot**

```{r, eval=FALSE}
## Make sure you have saved the residuals to the UN11 data frame before running
## the code below.

#ggplot(UN11) +
#  geom_line(mapping = aes(x = 1:dim(UN11)[1], y = residuals)) +
#  theme_bw() + 
#  scale_y_continuous(limits = c(-3.8, 3.8)) +
#  scale_x_continuous(limits = c(0, 200)) +
#  xlab("Order in Data Set") +
#  theme(axis.title.x = element_text(size = sz),
#        axis.title.y = element_text(size = sz),
#        axis.text = element_text(size = sz),
#        aspect.ratio = 1)
```


### 4. The errors are normally distributed.

**(a) Boxplot**


```{r, fig.align='center'}
UN11$residuals <- fert.lm$residuals
# The code below produces a basic boxplot
ggplot(data = UN11, mapping = aes(y = residuals)) + 
  geom_boxplot() + 
  scale_x_discrete() + 
  labs(title = "Residual Boxplot")
## <additional code here to make the plot look pretty>
```

The boxplot shows asymmetry, since the upper wiser is much longer than the lower one.
Also, the median is not in the middle of the box, again indicating asymmetry.  The 
normality assumption is violated.

**(b) Histogram**


```{r, fig.align='center'}
# The code below produces a basic histogram, together with a normal density 
# having mean and standard deviation equal to the sample mean and standard deviation of the residuals
ggplot(data = UN11, mapping = aes(x = residuals)) + 
  geom_histogram(mapping = aes(y = ..density..), binwidth = 0.5) +
  stat_function(fun = dnorm, color = "red", size = 2,
                args = list(mean = mean(UN11$residuals), 
                            sd = sd(UN11$residuals))) + 
  labs(x = "Residuals", y = "Density", title = "Residual Histogram")
## <additional code here to make the plot look pretty>
```

Similar to the boxplot, the distribution has a right skew.  Here, we also see 
that the shape of the histogram does not match the proper normal distribution, 
shown as the red curve, very well.  Normality is violated.

**(c) Normal QQ Plot**

```{r, fig.align='center'}
## 'which = 2' produces the normal QQ plot

autoplot(fert.lm, which = 2, ncol = 1, nrow = 1)  +
  theme_bw() + 
 scale_y_continuous(limits = c(-2, 3.2)) +
  theme(axis.title.x = element_text(size = sz),
        axis.title.y = element_text(size = sz),
        axis.text = element_text(size = sz),
        aspect.ratio = 1)
```

The right skey is also visible here, with the smallest and largest standardized
residuals falling above the dashed line, indicating they are larger than would 
be expected under normality.  Normality is violated.

## Corrections

**(a) Transform x** Given our assessment of the assumptions, we will want to perform some kind of transformation. We will use the power transformations to first find a suitable transform for `ppgdp` to improve the linearity.  Use the `invTranPlot` function to compare the square-root and logarithmic transformations with the untransformed predictor.

```{r, fig.align='center'}
## Fill in the appropriate values for the argument 'lambda'.  Setting 'optimal = TRUE'
## tells R to find the "best" power transformation, i.e. the one that minimizes RSS
invTranPlot(fertility ~ ppgdp, data = UN11, lambda = c(1, 0.5, 1), optimal = TRUE)
```

Although $\hat{\lambda} = -0.35$ is the "best" transformation, the plot shows that $\lambda = 0$ (the log transformation) also results in a model fit that represents
the relationship between fertility and per capita GDP fairly accurately.  Refit the linear regression model with `log(ppgdp)` as predictor, and call it `fert.transx.lm`.

```{r}
fert.transx.lm <- lm(fertility ~ log(ppgdp), data = UN11)
```

**(b) Check Linearity** Create the residuals versus fitted values plot for the new model, and confirm that the linearity assumption is still not satisfied.

```{r}
autoplot(fert.transxy.lm, which = 1, ncol = 1, nrow = 1) +
  theme_bw() + 
  scale_y_continuous(limits = c(-1.5, 2)) +
  scale_x_continuous(limits = c(0.5, 1.5)) +
  theme(axis.title.x = element_text(size = sz),
        axis.title.y = element_text(size = sz),
        axis.text = element_text(size = sz),
        aspect.ratio = 1)
```

**(c) Transform Y** Compute the Box-Cox transformation, and report the maximu likelihood estimate of $\lambda$. Explain why the logarithm transformation makes sense for the response.

```{r}
## Uncomment and run the code below
bc = boxCox(fert.transx.lm) # this will produce the plot
lambda.opt = bc$x[which.max(bc$y)] # this is the "best" lambda for Y
lambda.opt # print the maximum likelihood estimate
```
Although the optimal power is around -0.34, a 95% confidence interval nearly contains 0, 
which is a much more interpretable value.  We should try the logarithm transformation first, 
but possibly return to another transformation if that model does not satisfy the assumptions.

**(d) Final Model Fit** Refit the linear regression model using logarithmic transformations for both the predictor and response.  Call the fitted model `fert.transxy.lm`.

```{r}
fert.transxy.lm <- lm(log(fertility) ~ log(ppgdp), data = UN11)
```

**(e) Plot in Original Scale** It can be informative to view the model fit in the original scale, where it appears as a curve. Here is how you plot the transformed regression model on original scale of the data.  Note: Once you have fit the transformed regression model above (which you should name `fert.transxy.lm`), remove the argument "eval = FALSE" from the R chunk opening below.  Otherwise, the code below will not be run when you knit this file.

```{r eval=TRUE} 
# Sequence of ppgdp values that I am interested in using to predict fertility 
pred.vals <- seq(min(UN11$ppgdp), max(UN11$ppgdp), length = 100)  
# Predictions of log(fertility)
preds.trans <- fert.transxy.lm$coefficients[1] + 
  fert.transxy.lm$coefficients[2] * log(pred.vals)
# Predictions of fertility
preds.orig <- exp(preds.trans)  # use exp to "undo" log transform
preds <- data.frame("pred.vals" = pred.vals, "pred_orig" = preds.orig)

fert.base.plot.curve <- ggplot(data = UN11, 
                               mapping = aes(x = ppgdp, y = fertility)) +
  geom_point() +
  theme_bw() +
  scale_x_continuous(limits = c(0, 105100)) +
  scale_y_continuous(limits = c(0, 7)) +
  theme(aspect.ratio = 1)

fert.base.plot.curve + 
  geom_line(data = preds, 
            aes(x = pred.vals, y = pred_orig), 
            size = 1.5, color ="blue")
```

## Re-Check Assumptions

Go through each of the diagnostic plots one last time for the final model, and verify that each of the assumptions
seems plausible based on these plots.

### 1. Linearity

**(a) Scatterplot**

```{r, fig.align='center'}
fert.transxy.plot <- ggplot(data = UN11, mapping = aes(x = log(ppgdp), y = log(fertility))) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE)
  labs(x = "Per Capita GDP (US Dollars), Log Scale", y = "Fertility (#Children per Woman, Log Scale)")
fert.transxy.plot
```

The trend now appears to be linear.

**(b) Residuals vs. Fitted Values Plot**


```{r, fig.align='center'}
autoplot(fert.transxy.lm, which = 1, ncol = 1, nrow = 1) +
  theme_bw() + 
  scale_y_continuous(limits = c(-0.8, 1)) +
  scale_x_continuous(limits = c(0.25, 1.7)) +
  theme(axis.title.x = element_text(size = sz),
        axis.title.y = element_text(size = sz),
        axis.text = element_text(size = sz),
        aspect.ratio = 1)

```

The residuals now appear to be scattered around 0 for all fitted values.  Linearity
seems to hold.

### 2. Equal Variance

**(a) Scale-Location plot **

```{r, fig.align='center'}
autoplot(fert.transxy.lm, which = 3, ncol = 1, nrow = 1) +
  theme_bw() + 
  scale_y_continuous(limits = c(0, 1.8)) +
  scale_x_continuous(limits = c(0.25, 1.7)) +
  theme(axis.title.x = element_text(size = sz),
        axis.title.y = element_text(size = sz),
        axis.text = element_text(size = sz),
        aspect.ratio = 1)
```

The spread is now more constant across fitted values, evidenced by the fairly 
flat blue curve and that the largest residuals are all around 1.5 for all fitted values. 
There is no strong evidence against equal variance.

### 4. The errors are normally distributed.

**(a) Boxplot**


```{r, fig.align='center'}
UN11$transxy.residuals <- fert.transxy.lm$residuals
# The code below produces a basic boxplot
ggplot(data = UN11, mapping = aes(y = transxy.residuals)) + 
  geom_boxplot() + 
  scale_x_discrete() + 
  labs(title = "Residual Boxplot")
```

The distribution is extremely symmetric, so no clear violations of normality.

**(b) Histogram**

```{r, fig.align='center'}
ggplot(data = UN11, mapping = aes(x = transxy.residuals)) + 
  geom_histogram(mapping = aes(y = ..density..), binwidth = 0.1) +
  stat_function(fun = dnorm, color = "red", size = 2,
                args = list(mean = mean(UN11$transxy.residuals), 
                            sd = sd(UN11$transxy.residuals))) + 
  labs(x = "Residuals", y = "Density", title = "Residual Histogram")
```

The shape of the histogram is more symmetric and generally matches the red normal
density curve, so normality is supported.

**(c) Normal QQ Plot**

```{r, fig.align='center'}
autoplot(fert.transxy.lm, which = 2, ncol = 1, nrow = 1)  +
  theme_bw() + 
 scale_y_continuous(limits = c(-3, 3.2)) +
  theme(axis.title.x = element_text(size = sz),
        axis.title.y = element_text(size = sz),
        axis.text = element_text(size = sz),
        aspect.ratio = 1)
```

The data points follow the line quite well.  Some deviation for the largest and 
smallest standardized residuals may indicate that the errors are not exactly normally 
distributed, but this is not a huge concern, particularly since the sampe size is
fairly large.


## Repeat

We will not do this here, but it would be good to try a few more transformations, view the diagnostics, and from there determine the "best" model fit among all the transformed models.

## Summary and Conclusions

*Always* start by plotting your data (exploratory data analysis: view data, create scatterplot, summarize data, etc.) before jumping into an analysis or fitting a model. The scatterplot of `fertility` vs. `ppgdp` was obviously nonlinear, and the diagnostic plots verified that observation. After transforming ppgdp, there was still some evidence of nonlinearity, unequal variance, and non-normality. To fix this, we applied a Box-Cox approach and determined the log transform would be the best transformation for fertility. We applied this transformation, refit the model, and re-checked the assumptions. The assumptions all appear to be met. In practice, we could try additional transformations, compare the transformed models, and then pick the best model. Once we have a model that satisfies the assumptions, we can look at our model coefficients and p-values and safely draw conclusions.

Note: The ordinary way of interpreting coefficients is sometimes not useful if one or more of the variables is transformed.  In this example, a unit change of `log(ppgdp)` is not very meaningful.  As we will see in Module 3, however, the log transformation is very nice for interpretation since it corresponds to percentage changes instead of unit changes.  For example, to interpret the slope of -0.207 from the transformed model, we would say, "For every 10% increase in per capita GDP, average fertility decreases by 1.95%."

